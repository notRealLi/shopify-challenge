{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Fault In Our AOV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *The Problem*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On Shopify, we have exactly 100 sneaker shops, and each of these shops sells only one model of shoe. We want to do some analysis of the average order value (AOV). When we look at orders data over a 30 day window, we naively calculate an AOV of `$`3145.13. Given that we know these shops are selling sneakers, a relatively affordable item, something seems wrong with our analysis. \n",
    "#### 1. Think about what could be going wrong with our calculation. Think about a better way to evaluate this data. \n",
    "#### 2. What metric would you report for this dataset?\n",
    "#### 3. What is its value?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Analysis*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's take a peek at the data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          shop_id  user_id  order_amount  total_items payment_method  \\\n",
      "order_id                                                               \n",
      "1              53      746           224            2           cash   \n",
      "2              92      925            90            1           cash   \n",
      "3              44      861           144            1           cash   \n",
      "4              18      935           156            1    credit_card   \n",
      "5              18      883           156            1    credit_card   \n",
      "\n",
      "                   created_at  \n",
      "order_id                       \n",
      "1         2017-03-13 12:36:56  \n",
      "2         2017-03-03 17:38:52  \n",
      "3          2017-03-14 4:23:56  \n",
      "4         2017-03-26 12:43:37  \n",
      "5          2017-03-01 4:35:11  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vSvtQCCuNgG8S30A7fhO0ndjSxzAyL154_NUNCcJ5dwAV_DPBC67dxx3AM7jiQuVmPVVoyw18OyVBVF/pub?gid=0&single=true&output=csv')\n",
    "df.set_index('order_id', inplace=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see that each row corresponds to one order. Let's look at a summary of relevant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        order_amount  total_items\n",
      "count    5000.000000   5000.00000\n",
      "mean     3145.128000      8.78720\n",
      "std     41282.539349    116.32032\n",
      "min        90.000000      1.00000\n",
      "25%       163.000000      1.00000\n",
      "50%       284.000000      2.00000\n",
      "75%       390.000000      3.00000\n",
      "max    704000.000000   2000.00000\n"
     ]
    }
   ],
   "source": [
    "order_details_df = df[['order_amount', 'total_items']]\n",
    "\n",
    "orders_description = order_details_df.describe()\n",
    "print(orders_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Immediately from the description of the data frame, we can tell that the average order value (AOV) was calculated in the same way as the mean value of order amount, which is `$`3145.13. \n",
    "#### And we can see that the maximum value of the order amount `$`704,000.00 is abnormally higher than the average. This is most likely the reason why we got such an absurd figure for the AOV. Let's investigate further by looking at orders with out-of-ordinary values (higher than `$`10,000). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          shop_id  user_id  order_amount  total_items payment_method  \\\n",
      "order_id                                                               \n",
      "16             42      607        704000         2000    credit_card   \n",
      "61             42      607        704000         2000    credit_card   \n",
      "161            78      990         25725            1    credit_card   \n",
      "491            78      936         51450            2          debit   \n",
      "494            78      983         51450            2           cash   \n",
      "\n",
      "                   created_at  \n",
      "order_id                       \n",
      "16         2017-03-07 4:00:00  \n",
      "61         2017-03-04 4:00:00  \n",
      "161        2017-03-12 5:56:57  \n",
      "491       2017-03-26 17:08:19  \n",
      "494       2017-03-16 21:39:35  \n"
     ]
    }
   ],
   "source": [
    "abnormal_df = df[df['order_amount'] > 10000]\n",
    "print(abnormal_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From here we can see that high value orders are placed at certain shops. There are 2 of those shops it seems. Let's confirm by counting unique shop ID's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shop_id    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(abnormal_df['shop_id']).apply(pd.Series.nunique))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are indeed 2 shops where high value orders occur. Though the circumstances of orders placed at each shop don't seem to be similar. Let's look at them separately. First, shop 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          shop_id  user_id  order_amount  total_items payment_method  \\\n",
      "order_id                                                               \n",
      "16             42      607        704000         2000    credit_card   \n",
      "61             42      607        704000         2000    credit_card   \n",
      "521            42      607        704000         2000    credit_card   \n",
      "1105           42      607        704000         2000    credit_card   \n",
      "1363           42      607        704000         2000    credit_card   \n",
      "1437           42      607        704000         2000    credit_card   \n",
      "1563           42      607        704000         2000    credit_card   \n",
      "1603           42      607        704000         2000    credit_card   \n",
      "2154           42      607        704000         2000    credit_card   \n",
      "2298           42      607        704000         2000    credit_card   \n",
      "2836           42      607        704000         2000    credit_card   \n",
      "2970           42      607        704000         2000    credit_card   \n",
      "3333           42      607        704000         2000    credit_card   \n",
      "4057           42      607        704000         2000    credit_card   \n",
      "4647           42      607        704000         2000    credit_card   \n",
      "4869           42      607        704000         2000    credit_card   \n",
      "4883           42      607        704000         2000    credit_card   \n",
      "\n",
      "                  created_at  unit_price  \n",
      "order_id                                  \n",
      "16        2017-03-07 4:00:00       352.0  \n",
      "61        2017-03-04 4:00:00       352.0  \n",
      "521       2017-03-02 4:00:00       352.0  \n",
      "1105      2017-03-24 4:00:00       352.0  \n",
      "1363      2017-03-15 4:00:00       352.0  \n",
      "1437      2017-03-11 4:00:00       352.0  \n",
      "1563      2017-03-19 4:00:00       352.0  \n",
      "1603      2017-03-17 4:00:00       352.0  \n",
      "2154      2017-03-12 4:00:00       352.0  \n",
      "2298      2017-03-07 4:00:00       352.0  \n",
      "2836      2017-03-28 4:00:00       352.0  \n",
      "2970      2017-03-28 4:00:00       352.0  \n",
      "3333      2017-03-24 4:00:00       352.0  \n",
      "4057      2017-03-28 4:00:00       352.0  \n",
      "4647      2017-03-02 4:00:00       352.0  \n",
      "4869      2017-03-22 4:00:00       352.0  \n",
      "4883      2017-03-25 4:00:00       352.0  \n"
     ]
    }
   ],
   "source": [
    "shop_42_df = abnormal_df.loc[abnormal_df['shop_id'] == 42].copy()\n",
    "shop_42_df['unit_price'] = shop_42_df['order_amount'] / shop_42_df['total_items']\n",
    "print(shop_42_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The abnormal orders placed at shop 42 are rather curious. The were all made by the same user,  of the same quantity and at the same time of the day (4:00:00).   \n",
    "\n",
    "#### I believe these orders occur too often to be just erroneous data. The other possibility I could think of is that the user ordered these sneakers in large quantities for resale purposes. And he or she set up an automatic re-ordering for re-stocking.  \n",
    "\n",
    "#### Let us then look at the shop 78."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          shop_id  user_id  order_amount  total_items payment_method  \\\n",
      "order_id                                                               \n",
      "161            78      990         25725            1    credit_card   \n",
      "491            78      936         51450            2          debit   \n",
      "494            78      983         51450            2           cash   \n",
      "512            78      967         51450            2           cash   \n",
      "618            78      760         51450            2           cash   \n",
      "\n",
      "                   created_at  unit_price  \n",
      "order_id                                   \n",
      "161        2017-03-12 5:56:57     25725.0  \n",
      "491       2017-03-26 17:08:19     25725.0  \n",
      "494       2017-03-16 21:39:35     25725.0  \n",
      "512        2017-03-09 7:23:14     25725.0  \n",
      "618       2017-03-18 11:18:42     25725.0  \n"
     ]
    }
   ],
   "source": [
    "shop_78_df = abnormal_df.loc[abnormal_df['shop_id'] == 78].copy()\n",
    "shop_78_df['unit_price'] = shop_78_df['order_amount'] / shop_78_df['total_items']\n",
    "print(shop_78_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Answers*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see that the occurrences of high value orders at shop 78 were simply due to the fact that the shop sells an expensive brand of sneaker, priced at \\$25725.00 a pair.\n",
    "\n",
    "#### In both cases, the data was legitimate. So I don't think it would be appropriate to simply drop them. Perhaps we should group the data and have separate metrics for difference groups of data. There are several ways to do this:\n",
    "\n",
    "##### 1.) Grouping the data by shops. I think this method is feasible in this case because the outliers occur due to the uncommon natures of some shops (sales of high-priced products and offering wholesale service)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shop_id\n",
      "1    308.82\n",
      "2    174.33\n",
      "3    305.25\n",
      "4    258.51\n",
      "5    290.31\n",
      "Name: order_amount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(round(df.groupby('shop_id')['order_amount'].mean(), 2).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.) Grouping the data by types of orders, retail orders vs. wholesale orders. For the purpose of classifying the orders, we define orders with quantity less than 10 as retail orders and those with 10 or more as wholesale orders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retail AOV: $754.09\n",
      "Wholesale AOV: $704000.0\n"
     ]
    }
   ],
   "source": [
    "retail_df = df[df['total_items'] < 10]\n",
    "wholesale_df = df[df['total_items'] >= 10]\n",
    "\n",
    "\n",
    "print('Retail AOV: $' + str(round(retail_df['order_amount'].mean(), 2)))\n",
    "print('Wholesale AOV: $' + str(round(wholesale_df['order_amount'].mean(), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.) Grouping the data by users. This approach could provide us insights into the total dollar value of each user. This could be helpful for when audience-targeting related desicions need to be made (discriminatory pricing, targeted ads etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id\n",
      "607    704000.00\n",
      "700       299.38\n",
      "701       397.08\n",
      "702       406.62\n",
      "703       380.69\n",
      "Name: order_amount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(round(df.groupby('user_id')['order_amount'].mean(), 2).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### However if we are required to come up with a SINGLE-value metric for the dataset, the first thing comes to mind is median. In the presence of large outliers, median is better than mean but it definitely leaves some information in the dataset unused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order amount median: $284.0\n"
     ]
    }
   ],
   "source": [
    "print('Order amount median: $' + str(round(df['order_amount'].median(), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I don't think mode would be a very appropriate metric in this case. As shown below, \"Order amounts\" has large standard deviation and min-max difference, which means the value of a single order varies a lot. There are 258 unique values for order amount. If one of them happens to ocur the most often (`$`153.00), it does not represent the overall data that well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count      5000.000000\n",
      "mean       3145.128000\n",
      "std       41282.539349\n",
      "min          90.000000\n",
      "25%         163.000000\n",
      "50%         284.000000\n",
      "75%         390.000000\n",
      "max      704000.000000\n",
      "Name: order_amount, dtype: float64\n",
      "\n",
      "order_amount    258\n",
      "dtype: int64\n",
      "\n",
      "Order amount mode: $153\n"
     ]
    }
   ],
   "source": [
    "print(df['order_amount'].describe())\n",
    "print()\n",
    "print(pd.DataFrame(df['order_amount']).apply(pd.Series.nunique))\n",
    "print('\\nOrder amount mode: $' + str(round(df['order_amount'].mode()[0], 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In my opinion, each of the mean (AOV), median, and mode provides different insights about the dataset. For example, the mean (AOV) leans towards the higher value side, which means higher value orders represent most of the revenue. And the median combined with mean, tells us that the distribution is skewed to the right, in other words, there are more high value orders than low value ones. I don't think we could pick one of them as THE metric. Instead, we need to consider every one and the combination of different metrics when evaluating the dataset.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
